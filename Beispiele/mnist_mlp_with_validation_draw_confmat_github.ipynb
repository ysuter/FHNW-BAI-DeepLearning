{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysuter/FHNW-BAI-DeepLearning/blob/main/Beispiele/mnist_mlp_with_validation_draw_confmat_github.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qDO4c9G_eo1k",
      "metadata": {
        "id": "qDO4c9G_eo1k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fb294818",
      "metadata": {
        "id": "fb294818"
      },
      "source": [
        "# Beispiel Klassifikation handgeschriebener Ziffern des MNIST-Datensatzes — **MLP (Fully Connected)**\n",
        "\n",
        "Notebook fürs Training eines **fully connected networks (1 verborgene Scnhicht)** auf MNIST-Daten mit Bildern als 1D-Vektoren (28×28 → 784).  \n",
        "\n",
        "> Angepasst vom offiziellen [PyTorch MNIST Beispiel](https://github.com/pytorch/examples/blob/main/mnist/main.py).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "454ddb8e",
      "metadata": {
        "cellView": "form",
        "id": "454ddb8e"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies (Colab usually has these pre-installed)\n",
        "!pip -q install torch torchvision matplotlib tqdm pillow --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suADhg_yfp7H",
      "metadata": {
        "id": "suADhg_yfp7H"
      },
      "source": [
        "## Modell definieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EUdj-T2Bftku",
      "metadata": {
        "id": "EUdj-T2Bftku"
      },
      "outputs": [],
      "source": [
        "class FCNet(nn.Module):\n",
        "    def __init__(self, hidden=256, p_drop=0.2):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28*28, hidden)\n",
        "        self.drop = nn.Dropout(p_drop)\n",
        "        self.fc2 = nn.Linear(hidden, 10)\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "model = FCNet(hidden=cfg.hidden, p_drop=cfg.p_drop).to(device)\n",
        "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(model)\n",
        "print(f\"Trainable parameters: {n_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee487ad4",
      "metadata": {
        "id": "ee487ad4"
      },
      "outputs": [],
      "source": [
        "#@title MNIST: data, MLP model, training with validation, test, and visualization\n",
        "import os, math, random, io\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    batch_size: int = 64\n",
        "    test_batch_size: int = 1000\n",
        "    epochs: int = 5\n",
        "    lr: float = 1e-3\n",
        "    gamma: float = 0.7\n",
        "    log_interval: int = 100\n",
        "    val_size: int = 10000\n",
        "    use_amp: bool = True\n",
        "    num_workers: int = 2\n",
        "    hidden: int = 256\n",
        "    p_drop: float = 0.2\n",
        "\n",
        "cfg = Config()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])\n",
        "\n",
        "root = \"./data\"\n",
        "full_train = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(root, train=False, download=True, transform=transform)\n",
        "\n",
        "val_size = cfg.val_size\n",
        "train_size = len(full_train) - val_size\n",
        "generator = torch.Generator().manual_seed(SEED)\n",
        "train_ds, val_ds = random_split(full_train, [train_size, val_size], generator=generator)\n",
        "\n",
        "loader_train_kwargs = dict(batch_size=cfg.batch_size, shuffle=True)\n",
        "loader_eval_kwargs  = dict(batch_size=cfg.test_batch_size, shuffle=False)\n",
        "if device.type == \"cuda\":\n",
        "    loader_train_kwargs.update(num_workers=cfg.num_workers, pin_memory=True)\n",
        "    loader_eval_kwargs.update(num_workers=cfg.num_workers, pin_memory=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, **loader_train_kwargs)\n",
        "val_loader   = DataLoader(val_ds, **loader_eval_kwargs)\n",
        "test_loader  = DataLoader(mnist_test, **loader_eval_kwargs)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(mnist_test)}\")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=cfg.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp and device.type == \"cuda\")\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "train_history = {\"loss\": []}\n",
        "val_history = {\"loss\": [], \"acc\": []}\n",
        "\n",
        "def train_epoch(epoch):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Train Epoch {epoch}\")\n",
        "    for batch_idx, (data, target) in pbar:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running += loss.item() * data.size(0)\n",
        "        if batch_idx % cfg.log_interval == 0:\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    avg = running / len(train_loader.dataset)\n",
        "    train_history[\"loss\"].append(avg)\n",
        "    print(f\"Train avg loss: {avg:.4f}\")\n",
        "    return avg\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(loader, split_name=\"Val\"):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0.0, 0\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.item() * data.size(0)\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = correct / len(loader.dataset)\n",
        "    print(f\"{split_name}: avg loss {avg_loss:.4f}, acc {acc*100:.2f}% ({correct}/{len(loader.dataset)})\")\n",
        "    if split_name.lower().startswith(\"val\"):\n",
        "        val_history[\"loss\"].append(avg_loss)\n",
        "        val_history[\"acc\"].append(acc)\n",
        "    return avg_loss, acc\n",
        "\n",
        "BEST_PATH = \"best_mnist_val_fc.pt\"\n",
        "best_val_acc = -1.0\n",
        "for epoch in range(1, cfg.epochs + 1):\n",
        "    _ = train_epoch(epoch)\n",
        "    _, val_acc = evaluate(val_loader, \"Val\")\n",
        "    scheduler.step()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), BEST_PATH)\n",
        "        print(f\"✅ Saved new best MLP (val acc={best_val_acc*100:.2f}%)\")\n",
        "print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1); plt.plot(train_history[\"loss\"], label=\"train\"); plt.plot(val_history[\"loss\"], label=\"val\"); plt.title(\"Loss\"); plt.grid(True); plt.legend()\n",
        "plt.subplot(1,2,2); plt.plot(val_history[\"acc\"], label=\"val acc\"); plt.title(\"Validation Accuracy\"); plt.grid(True); plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model.load_state_dict(torch.load(BEST_PATH, map_location=device))\n",
        "_ = evaluate(test_loader, \"Test\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def show_batch_predictions(loader, n_images=16):\n",
        "    model.eval()\n",
        "    data, target = next(iter(loader))\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    preds = output.argmax(dim=1)\n",
        "    imgs = data.cpu()\n",
        "    cols = 8\n",
        "    rows = math.ceil(n_images / cols)\n",
        "    plt.figure(figsize=(cols*2, rows*2))\n",
        "    for i in range(n_images):\n",
        "        if i >= imgs.size(0): break\n",
        "        img = imgs[i,0]\n",
        "        img = img * 0.3081 + 0.1307  # denormalize\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img.numpy(), cmap=\"gray\")\n",
        "        plt.title(f\"P:{preds[i].item()} T:{target[i].item()}\", fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_batch_predictions(test_loader, n_images=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406a8ea7",
      "metadata": {
        "id": "406a8ea7"
      },
      "outputs": [],
      "source": [
        "#@title Confusion Matrix on the Test Set (Normalized)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_confusion_matrix(model, loader, device, num_classes=10, normalize=True, eps=1e-12):\n",
        "    model.eval()\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        pred = model(data).argmax(dim=1)\n",
        "        for t, p in zip(target.view(-1), pred.view(-1)):\n",
        "            cm[int(t.item()), int(p.item())] += 1\n",
        "    if normalize:\n",
        "        row_sums = cm.sum(axis=1, keepdims=True)\n",
        "        cm_norm = cm / np.maximum(row_sums, eps)\n",
        "        return cm, cm_norm\n",
        "    else:\n",
        "        return cm, None\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_mnist_val_fc.pt\", map_location=device))\n",
        "cm_raw, cm_norm = compute_confusion_matrix(model, test_loader, device, num_classes=10, normalize=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "im = ax.imshow(cm_norm, vmin=0.0, vmax=1.0, interpolation='nearest')\n",
        "ax.set_title('Normalized Confusion Matrix (Test)')\n",
        "ax.set_xlabel('Predicted label'); ax.set_ylabel('True label')\n",
        "ax.set_xticks(range(10)); ax.set_yticks(range(10))\n",
        "ax.set_xticklabels(range(10)); ax.set_yticklabels(range(10))\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        ax.text(j, i, f\"{cm_norm[i, j]*100:.1f}%\\n({cm_raw[i, j]})\",\n",
        "                ha='center', va='center', fontsize=7)\n",
        "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "per_class_acc = np.diag(cm_norm)\n",
        "overall_acc = np.trace(cm_raw) / cm_raw.sum()\n",
        "print(\"Per-class accuracy:\", np.round(per_class_acc, 4))\n",
        "print(\"Overall accuracy:\", round(overall_acc, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f53c5ee2",
      "metadata": {
        "id": "f53c5ee2"
      },
      "outputs": [],
      "source": [
        "#@title Collect and visualize misclassified test samples\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_misclassified(model, loader, device):\n",
        "    model.eval()\n",
        "    mis = []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        preds = probs.argmax(dim=1)\n",
        "        wrong = preds.ne(y)\n",
        "        if wrong.any():\n",
        "            idxs = torch.nonzero(wrong, as_tuple=False).squeeze(1)\n",
        "            for i in idxs:\n",
        "                mis.append({\n",
        "                    \"img\": x[i].detach().cpu(),\n",
        "                    \"true\": int(y[i].item()),\n",
        "                    \"pred\": int(preds[i].item()),\n",
        "                    \"pred_conf\": float(probs[i, preds[i]].item()),\n",
        "                    \"true_conf\": float(probs[i, y[i]].item())\n",
        "                })\n",
        "    return mis\n",
        "\n",
        "def denorm_mnist(t):\n",
        "    t = t.clone()\n",
        "    t = t * 0.3081 + 0.1307\n",
        "    return t\n",
        "\n",
        "def show_misclassified(mis, n=25, cols=5):\n",
        "    if len(mis) == 0:\n",
        "        print(\"No misclassified samples.\")\n",
        "        return\n",
        "    n = min(n, len(mis))\n",
        "    rows = math.ceil(n / cols)\n",
        "    plt.figure(figsize=(cols*2, rows*2))\n",
        "    for i in range(n):\n",
        "        m = mis[i]\n",
        "        img = denorm_mnist(m[\"img\"]).squeeze(0).numpy()\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img, cmap=\"gray\")\n",
        "        plt.title(f\"T:{m['true']}  P:{m['pred']}  ({m['pred_conf']:.2f})\", fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def show_misclassified_per_class(mis, k=5):\n",
        "    buckets = defaultdict(list)\n",
        "    for m in mis:\n",
        "        buckets[m[\"true\"]].append(m)\n",
        "    rows, cols = 10, k\n",
        "    plt.figure(figsize=(cols*2, rows*2))\n",
        "    idx = 1\n",
        "    for true_label in range(10):\n",
        "        items = buckets[true_label][:k]\n",
        "        for j in range(cols):\n",
        "            plt.subplot(rows, cols, idx); idx += 1\n",
        "            if j < len(items):\n",
        "                m = items[j]\n",
        "                img = denorm_mnist(m[\"img\"]).squeeze(0).numpy()\n",
        "                plt.imshow(img, cmap=\"gray\")\n",
        "                plt.title(f\"T:{true_label}→P:{m['pred']}\", fontsize=8)\n",
        "                plt.axis(\"off\")\n",
        "            else:\n",
        "                plt.axis(\"off\")\n",
        "    plt.suptitle(\"Misclassified per TRUE class (rows 0..9)\", y=0.92)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def show_hardest_errors(mis, n=25, by=\"margin\"):\n",
        "    if len(mis) == 0:\n",
        "        print(\"No misclassified samples.\")\n",
        "        return\n",
        "    if by == \"margin\":\n",
        "        ranked = sorted(mis, key=lambda m: m[\"pred_conf\"] - m[\"true_conf\"], reverse=True)\n",
        "    elif by == \"low_true\":\n",
        "        ranked = sorted(mis, key=lambda m: m[\"true_conf\"])\n",
        "    else:\n",
        "        ranked = mis\n",
        "    show_misclassified(ranked, n=n, cols=5)\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_mnist_val_fc.pt\", map_location=device))\n",
        "misclassified = collect_misclassified(model, test_loader, device)\n",
        "print(f\"Collected {len(misclassified)} misclassified samples.\")\n",
        "show_misclassified(misclassified, n=25, cols=5)\n",
        "# show_misclassified_per_class(misclassified, k=5)\n",
        "# show_hardest_errors(misclassified, n=20, by=\"margin\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45e4c3c0",
      "metadata": {
        "id": "45e4c3c0"
      },
      "outputs": [],
      "source": [
        "#@title Draw a digit (0–9) and classify with the trained MLP (with confidence chart)\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "from base64 import b64decode\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"best_mnist_val_fc.pt\", map_location=device))\n",
        "except Exception as e:\n",
        "    print(\"Warning: could not load best_mnist_val_fc.pt. Train the model first.\", e)\n",
        "\n",
        "js = Javascript('''\n",
        "async function draw_digit() {\n",
        "  return await new Promise((resolve) => {\n",
        "    const div = document.createElement('div');\n",
        "    div.style.margin = '8px 0';\n",
        "    const title = document.createElement('div');\n",
        "    title.textContent = 'Draw a digit (white on black). Click Predict.';\n",
        "    title.style.margin = '6px 0';\n",
        "    const canvas = document.createElement('canvas');\n",
        "    canvas.width = 280; canvas.height = 280;\n",
        "    canvas.style.border = '1px solid #999';\n",
        "    canvas.style.touchAction = 'none';\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    ctx.fillStyle = 'black'; ctx.fillRect(0,0,canvas.width,canvas.height);\n",
        "    let drawing=false;\n",
        "    function rel(e){const r=canvas.getBoundingClientRect(); return {x:e.clientX-r.left, y:e.clientY-r.top};}\n",
        "    canvas.addEventListener('mousedown', e=>{drawing=true; const p=rel(e); ctx.lineWidth=20; ctx.lineCap='round'; ctx.strokeStyle='white'; ctx.beginPath(); ctx.moveTo(p.x,p.y);});\n",
        "    canvas.addEventListener('mousemove', e=>{if(!drawing)return; const p=rel(e); ctx.lineTo(p.x,p.y); ctx.stroke();});\n",
        "    canvas.addEventListener('mouseup', ()=>{drawing=false;});\n",
        "    canvas.addEventListener('mouseleave', ()=>{drawing=false;});\n",
        "    canvas.addEventListener('touchstart', e=>{const r=canvas.getBoundingClientRect(); const t=e.touches[0]; drawing=true; ctx.lineWidth=20; ctx.lineCap='round'; ctx.strokeStyle='white'; ctx.beginPath(); ctx.moveTo(t.clientX-r.left,t.clientY-r.top); e.preventDefault();},{passive:false});\n",
        "    canvas.addEventListener('touchmove', e=>{if(!drawing)return; const r=canvas.getBoundingClientRect(); const t=e.touches[0]; ctx.lineTo(t.clientX-r.left,t.clientY-r.top); ctx.stroke(); e.preventDefault();},{passive:false});\n",
        "    canvas.addEventListener('touchend', ()=>{drawing=false;},{passive:false});\n",
        "    const btns=document.createElement('div'); btns.style.marginTop='6px';\n",
        "    const clearBtn=document.createElement('button'); clearBtn.textContent='Clear';\n",
        "    const predictBtn=document.createElement('button'); predictBtn.textContent='Predict';\n",
        "    clearBtn.style.marginRight='6px';\n",
        "    clearBtn.onclick=()=>{ctx.fillStyle='black'; ctx.fillRect(0,0,canvas.width,canvas.height);};\n",
        "    predictBtn.onclick=()=>{const dataURL=canvas.toDataURL('image/png'); resolve(dataURL); document.body.removeChild(div);};\n",
        "    btns.appendChild(clearBtn); btns.appendChild(predictBtn);\n",
        "    div.appendChild(title); div.appendChild(canvas); div.appendChild(btns);\n",
        "    document.body.appendChild(div);\n",
        "  });\n",
        "}\n",
        "''')\n",
        "display(js)\n",
        "dataURL = eval_js('draw_digit()')\n",
        "\n",
        "if dataURL.startswith('data:image/png;base64,'):\n",
        "    b64 = dataURL.split(',')[1]\n",
        "else:\n",
        "    b64 = dataURL\n",
        "\n",
        "import io\n",
        "img = Image.open(io.BytesIO(b64decode(b64))).convert('L')\n",
        "img_small = img.resize((28,28), Image.BILINEAR)\n",
        "arr = np.array(img_small).astype(np.float32)/255.0\n",
        "x = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)\n",
        "x = (x - 0.1307) / 0.3081\n",
        "x = x.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model(x)\n",
        "    probs = torch.softmax(out, dim=1).cpu().numpy().squeeze(0)  # normalized 0–1\n",
        "    pred = int(np.argmax(probs))\n",
        "\n",
        "print(f\"Predicted digit: {pred}\")\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
        "axs[0].imshow(arr, cmap='gray')\n",
        "axs[0].set_title(f'Input (Pred: {pred})')\n",
        "axs[0].axis('off')\n",
        "axs[1].bar(range(10), probs)\n",
        "axs[1].set_xticks(range(10))\n",
        "axs[1].set_ylim([0, 1])\n",
        "axs[1].set_xlabel(\"Digit\")\n",
        "axs[1].set_ylabel(\"Confidence\")\n",
        "axs[1].set_title(\"Confidence per class (0–9)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}