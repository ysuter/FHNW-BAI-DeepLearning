{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysuter/FHNW-BAI-DeepLearning/blob/main/Beispiele/mnist_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e09c82b",
      "metadata": {
        "id": "6e09c82b"
      },
      "source": [
        "# MNIST (PyTorch) — Colab with **Validation**, **Confusion Matrix**, and **Draw-to-Classify**\n",
        "Adapted from the official [PyTorch MNIST example](https://github.com/pytorch/examples/blob/main/mnist/main.py), extended with:\n",
        "- **Train/Val/Test** split (e.g., 50k / 10k / 10k)\n",
        "- Best-on-**validation** checkpoint\n",
        "- **Confusion Matrix** on test set\n",
        "- Interactive **canvas** to draw a digit and classify with the trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q9Ja9smJDvyP"
      },
      "id": "q9Ja9smJDvyP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4beaa3ca",
      "metadata": {
        "id": "4beaa3ca"
      },
      "outputs": [],
      "source": [
        "#@title Install/Check dependencies (Colab usually has these pre-installed)\n",
        "!pip -q install torch torchvision matplotlib tqdm pillow --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelldefinition"
      ],
      "metadata": {
        "id": "eCDvl1FtnbgA"
      },
      "id": "eCDvl1FtnbgA"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#  Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(64*12*12, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model = Net().to(device)\n",
        "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Trainable parameters: {n_params:,}\")"
      ],
      "metadata": {
        "id": "xrpl2On-nVfZ"
      },
      "id": "xrpl2On-nVfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4088a8f2",
      "metadata": {
        "id": "4088a8f2"
      },
      "outputs": [],
      "source": [
        "#@title MNIST: data, model, training (with validation), testing, and visualization\n",
        "import os, math, random\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "#  Config\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    batch_size: int = 64\n",
        "    test_batch_size: int = 1000\n",
        "    epochs: int = 3\n",
        "    lr: float = 1.0\n",
        "    gamma: float = 0.7\n",
        "    log_interval: int = 100\n",
        "    val_size: int = 10000\n",
        "    use_amp: bool = True\n",
        "    num_workers: int = 2\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "#  Data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])\n",
        "\n",
        "root = \"./data\"\n",
        "full_train = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(root, train=False, download=True, transform=transform)\n",
        "\n",
        "val_size = cfg.val_size\n",
        "train_size = len(full_train) - val_size\n",
        "generator = torch.Generator().manual_seed(SEED)\n",
        "train_ds, val_ds = random_split(full_train, [train_size, val_size], generator=generator)\n",
        "\n",
        "train_loader_kwargs = dict(batch_size=cfg.batch_size, shuffle=True)\n",
        "eval_loader_kwargs = dict(batch_size=cfg.test_batch_size, shuffle=False)\n",
        "if device.type == \"cuda\":\n",
        "    train_loader_kwargs.update(num_workers=cfg.num_workers, pin_memory=True)\n",
        "    eval_loader_kwargs.update(num_workers=cfg.num_workers, pin_memory=True)\n",
        "\n",
        "train_loader = DataLoader(train_ds, **train_loader_kwargs)\n",
        "val_loader   = DataLoader(val_ds,   **eval_loader_kwargs)\n",
        "test_loader  = DataLoader(mnist_test, **eval_loader_kwargs)\n",
        "\n",
        "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(mnist_test)}\")\n",
        "\n",
        "#  Optimizer & Scheduler\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=cfg.lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=cfg.gamma)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=cfg.use_amp and device.type == \"cuda\")\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#  Train / Eval\n",
        "train_history = {\"loss\": []}\n",
        "val_history = {\"loss\": [], \"acc\": []}\n",
        "\n",
        "def train_epoch(epoch):\n",
        "    model.train()\n",
        "    running = 0.0\n",
        "    pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Train Epoch {epoch}\")\n",
        "    for batch_idx, (data, target) in pbar:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=scaler.is_enabled()):\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running += loss.item() * data.size(0)\n",
        "        if batch_idx % cfg.log_interval == 0:\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    avg = running / len(train_loader.dataset)\n",
        "    train_history[\"loss\"].append(avg)\n",
        "    print(f\"Train avg loss: {avg:.4f}\")\n",
        "    return avg\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(loader, split_name=\"Val\"):\n",
        "    model.eval()\n",
        "    total_loss, correct = 0.0, 0\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.item() * data.size(0)\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    acc = correct / len(loader.dataset)\n",
        "    print(f\"{split_name}: avg loss {avg_loss:.4f}, acc {acc*100:.2f}% ({correct}/{len(loader.dataset)})\")\n",
        "    if split_name.lower().startswith(\"val\"):\n",
        "        val_history[\"loss\"].append(avg_loss)\n",
        "        val_history[\"acc\"].append(acc)\n",
        "    return avg_loss, acc\n",
        "\n",
        "#  Train Loop with best-on-val checkpoint\n",
        "BEST_PATH = \"best_mnist_val.pt\"\n",
        "best_val_acc = -1.0\n",
        "\n",
        "for epoch in range(1, cfg.epochs + 1):\n",
        "    _ = train_epoch(epoch)\n",
        "    _, val_acc = evaluate(val_loader, \"Val\")\n",
        "    scheduler.step()\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), BEST_PATH)\n",
        "        print(f\"✅ Saved new best model (val acc={best_val_acc*100:.2f}%)\")\n",
        "\n",
        "print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
        "\n",
        "# ---------------------- Plots ----------------------\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(1,2,1); plt.plot(train_history[\"loss\"], label=\"train\"); plt.plot(val_history[\"loss\"], label=\"val\"); plt.title(\"Loss\"); plt.grid(True); plt.legend()\n",
        "plt.subplot(1,2,2); plt.plot(val_history[\"acc\"], label=\"val acc\"); plt.title(\"Validation Accuracy\"); plt.grid(True); plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ---------------------- Test evaluation ----------------------\n",
        "model.load_state_dict(torch.load(BEST_PATH, map_location=device))\n",
        "_ = evaluate(test_loader, \"Test\")\n",
        "\n",
        "# ---------------------- Visualize predictions ----------------------\n",
        "@torch.no_grad()\n",
        "def show_batch_predictions(loader, n_images=16):\n",
        "    model.eval()\n",
        "    data, target = next(iter(loader))\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    preds = output.argmax(dim=1)\n",
        "    imgs = data.cpu()\n",
        "    cols = 8\n",
        "    rows = math.ceil(n_images / cols)\n",
        "    plt.figure(figsize=(cols*2, rows*2))\n",
        "    for i in range(n_images):\n",
        "        if i >= imgs.size(0): break\n",
        "        img = imgs[i,0]\n",
        "        img = img * 0.3081 + 0.1307  # denormalize\n",
        "        plt.subplot(rows, cols, i+1)\n",
        "        plt.imshow(img.numpy(), cmap=\"gray\")\n",
        "        plt.title(f\"P:{preds[i].item()} T:{target[i].item()}\", fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_batch_predictions(test_loader, n_images=16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66df714c",
      "metadata": {
        "id": "66df714c"
      },
      "outputs": [],
      "source": [
        "#@title Confusion Matrix on the Test Set\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def compute_confusion_matrix(model, loader, device, num_classes=10, normalize=True, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Returns (cm_raw, cm_norm) where:\n",
        "      - cm_raw: integer counts (num_classes x num_classes), rows=true, cols=pred\n",
        "      - cm_norm: row-normalized (each row sums to 1.0) if normalize=True, else None\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=np.int64)\n",
        "\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        pred = model(data).argmax(dim=1)\n",
        "        for t, p in zip(target.view(-1), pred.view(-1)):\n",
        "            cm[int(t.item()), int(p.item())] += 1\n",
        "\n",
        "    if normalize:\n",
        "        row_sums = cm.sum(axis=1, keepdims=True)\n",
        "        cm_norm = cm / np.maximum(row_sums, eps)\n",
        "        return cm, cm_norm\n",
        "    else:\n",
        "        return cm, None\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_mnist_val.pt\", map_location=device))\n",
        "cm_raw, cm_norm = compute_confusion_matrix(model, test_loader, device, num_classes=10)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "im = ax.imshow(cm_norm, interpolation='nearest')\n",
        "ax.set_title('Confusion Matrix (Test)')\n",
        "ax.set_xlabel('Predicted label')\n",
        "ax.set_ylabel('True label')\n",
        "ax.set_xticks(range(10)); ax.set_yticks(range(10))\n",
        "ax.set_xticklabels(list(range(10))); ax.set_yticklabels(list(range(10)))\n",
        "for i in range(10):\n",
        "    for j in range(10):\n",
        "        ax.text(j, i, int(cm_raw[i, j]), ha='center', va='center', fontsize=8)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "totals = cm_raw.sum(axis=1).astype(np.float64)\n",
        "with np.errstate(divide='ignore', invalid='ignore'):\n",
        "    per_class_acc = np.divide(np.diag(cm_raw), totals, out=np.zeros_like(totals), where=totals>0)\n",
        "print(\"Per-class accuracy:\", np.round(per_class_acc, 4))\n",
        "print(\"Overall accuracy:\", round(np.trace(cm_raw) / cm_raw.sum(), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2dd1ffc",
      "metadata": {
        "id": "a2dd1ffc"
      },
      "outputs": [],
      "source": [
        "#@title Draw a digit (0–9) and classify with the trained model\n",
        "# Draw white digit on black canvas. Click Predict to send to Python for classification.\n",
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, Javascript\n",
        "from base64 import b64decode\n",
        "import io\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"best_mnist_val.pt\", map_location=device))\n",
        "except Exception as e:\n",
        "    print(\"Warning: could not load best_mnist_val.pt. Train the model first.\", e)\n",
        "\n",
        "js = Javascript('''\n",
        "async function draw_digit() {\n",
        "  return await new Promise((resolve) => {\n",
        "    const div = document.createElement('div');\n",
        "    div.style.margin = '8px 0';\n",
        "    const title = document.createElement('div');\n",
        "    title.textContent = 'Draw a digit (white on black). Click Predict.';\n",
        "    title.style.margin = '6px 0';\n",
        "    const canvas = document.createElement('canvas');\n",
        "    canvas.width = 280; canvas.height = 280;\n",
        "    canvas.style.border = '1px solid #999';\n",
        "    canvas.style.touchAction = 'none';\n",
        "    const ctx = canvas.getContext('2d');\n",
        "    ctx.fillStyle = 'black'; ctx.fillRect(0,0,canvas.width,canvas.height);\n",
        "    let drawing=false;\n",
        "    function rel(e){const r=canvas.getBoundingClientRect(); return {x:e.clientX-r.left, y:e.clientY-r.top};}\n",
        "    canvas.addEventListener('mousedown', e=>{drawing=true; const p=rel(e); ctx.lineWidth=20; ctx.lineCap='round'; ctx.strokeStyle='white'; ctx.beginPath(); ctx.moveTo(p.x,p.y);});\n",
        "    canvas.addEventListener('mousemove', e=>{if(!drawing)return; const p=rel(e); ctx.lineTo(p.x,p.y); ctx.stroke();});\n",
        "    canvas.addEventListener('mouseup', ()=>{drawing=false;});\n",
        "    canvas.addEventListener('mouseleave', ()=>{drawing=false;});\n",
        "    canvas.addEventListener('touchstart', e=>{const r=canvas.getBoundingClientRect(); const t=e.touches[0]; drawing=true; ctx.lineWidth=20; ctx.lineCap='round'; ctx.strokeStyle='white'; ctx.beginPath(); ctx.moveTo(t.clientX-r.left,t.clientY-r.top); e.preventDefault();},{passive:false});\n",
        "    canvas.addEventListener('touchmove', e=>{if(!drawing)return; const r=canvas.getBoundingClientRect(); const t=e.touches[0]; ctx.lineTo(t.clientX-r.left,t.clientY-r.top); ctx.stroke(); e.preventDefault();},{passive:false});\n",
        "    canvas.addEventListener('touchend', ()=>{drawing=false;},{passive:false});\n",
        "    const btns=document.createElement('div'); btns.style.marginTop='6px';\n",
        "    const clearBtn=document.createElement('button'); clearBtn.textContent='Clear';\n",
        "    const predictBtn=document.createElement('button'); predictBtn.textContent='Predict';\n",
        "    clearBtn.style.marginRight='6px';\n",
        "    clearBtn.onclick=()=>{ctx.fillStyle='black'; ctx.fillRect(0,0,canvas.width,canvas.height);};\n",
        "    predictBtn.onclick=()=>{const dataURL=canvas.toDataURL('image/png'); resolve(dataURL); document.body.removeChild(div);};\n",
        "    btns.appendChild(clearBtn); btns.appendChild(predictBtn);\n",
        "    div.appendChild(title); div.appendChild(canvas); div.appendChild(btns);\n",
        "    document.body.appendChild(div);\n",
        "  });\n",
        "}\n",
        "''')\n",
        "display(js)\n",
        "dataURL = eval_js('draw_digit()')\n",
        "\n",
        "if dataURL.startswith('data:image/png;base64,'):\n",
        "    b64 = dataURL.split(',')[1]\n",
        "else:\n",
        "    b64 = dataURL\n",
        "\n",
        "img = Image.open(io.BytesIO(b64decode(b64))).convert('L')\n",
        "img_small = img.resize((28,28), Image.BILINEAR)\n",
        "arr = np.array(img_small).astype(np.float32)/255.0\n",
        "x = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)\n",
        "x = (x - 0.1307) / 0.3081\n",
        "x = x.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model(x)\n",
        "    probs = torch.softmax(out, dim=1)\n",
        "    pred = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "print(f\"Predicted digit: {pred}\")\n",
        "print(\"Probabilities:\", probs.squeeze(0).cpu().numpy())\n",
        "\n",
        "# Plot the processed input + confidence bar chart\n",
        "fig, axs = plt.subplots(1,2, figsize=(8,3))\n",
        "axs[0].imshow(arr, cmap='gray')\n",
        "axs[0].set_title(f'Input (Pred: {pred})')\n",
        "axs[0].axis('off')\n",
        "axs[1].bar(range(10), probs.cpu().numpy().squeeze())\n",
        "axs[1].set_xticks(range(10))\n",
        "axs[1].set_ylim([0,1])\n",
        "axs[1].set_title(\"Confidence per class\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}